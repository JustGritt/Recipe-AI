---
import Microphone from "@icons/Microphone.astro"
---
<script>
    type MessageRole = 'user' | 'assistant';

    interface ConversationMessage {
      role: MessageRole;
      content: string;
    }

    let transcript: string = '';
    let isListening: boolean = false;
    let conversation: ConversationMessage[] = [];

    let recognition: SpeechRecognition | undefined;

    function renderConversation(): void {
      const conversationElement = document.getElementById('conversation');
      if (conversationElement) {
        conversationElement.innerHTML = '';
        conversation.forEach((message, index) => {
          const div = document.createElement('div');
          div.classList.add(message.role === 'user' ? 'user-message' : 'assistant-message');
          div.innerHTML = `<p>${message.content}</p>`;

          if (message.role === 'user') {
            const deleteButton = document.createElement('button');
            deleteButton.textContent = 'Delete';
            deleteButton.addEventListener('click', () => handleDelete(index));
            div.appendChild(deleteButton);
          }

          conversationElement.appendChild(div);
        });
      }
    }

    function handleDelete(index: number): void {
        const updatedConversation = [...conversation];
        updatedConversation.splice(index, 1);

        if (index < updatedConversation.length && updatedConversation[index].role === 'assistant') {
        updatedConversation.splice(index, 1);
        }

        conversation = updatedConversation;
        renderConversation();
    }

    function startListening(): void {
  const startListeningBtn = document.getElementById('start-listening');
  const chatWindowInputText = document.querySelector('#chat-window-input input') as HTMLInputElement;
  if (window.SpeechRecognition || (window as any).webkitSpeechRecognition) {
    recognition = new (window.SpeechRecognition || (window as any).webkitSpeechRecognition)();

    recognition.onstart = () => {
      isListening = true;
      // Set Pause icon when listening starts
      startListeningBtn!.innerHTML = `
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" class="w-6 h-6">
          <path fill-rule="evenodd" d="M6.75 5.25a.75.75 0 01.75-.75H9a.75.75 0 01.75.75v13.5a.75.75 0 01-.75.75H7.5a.75.75 0 01-.75-.75V5.25zM14.25 5.25a.75.75 0 01.75-.75H17a.75.75 0 01.75.75v13.5a.75.75 0 01-.75.75h-1.5a.75.75 0 01-.75-.75V5.25z" clip-rule="evenodd" />
        </svg>`;
    };

    recognition.onresult = (event: SpeechRecognitionEvent) => {
      const lastResultIndex = event.results.length - 1;
      const recognizedText = event.results[lastResultIndex][0].transcript;
      transcript = recognizedText;
      chatWindowInputText!.value = transcript;
    };

    recognition.onend = () => {
      isListening = false;
      // Set Microphone icon when listening ends
      startListeningBtn!.innerHTML = `
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" class="w-6 h-6">
          <path d="M8.25 4.5a3.75 3.75 0 1 1 7.5 0v8.25a3.75 3.75 0 1 1-7.5 0V4.5Z" />
          <path d="M6 10.5a.75.75 0 0 1 .75.75v1.5a5.25 5.25 0 1 0 10.5 0v-1.5a.75.75 0 0 1 1.5 0v1.5a6.751 6.751 0 0 1-6 6.709v2.291h3a.75.75 0 0 1 0 1.5h-7.5a.75.75 0 0 1 0-1.5h3v-2.291a6.751 6.751 0 0 1-6-6.709v-1.5A.75.75 0 0 1 6 10.5Z" />
        </svg>`;
    };

    recognition.onerror = (event: SpeechRecognitionError) => {
      isListening = false;
      // Set Play icon on error for visibility
      startListeningBtn!.innerHTML = `
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" class="w-6 h-6 text-red-600">
          <path fill-rule="evenodd" d="M4.5 5.653c0-1.427 1.529-2.33 2.779-1.643l11.54 6.347c1.295.712 1.295 2.573 0 3.286L7.28 19.99c-1.25.687-2.779-.217-2.779-1.643V5.653z" clip-rule="evenodd" />
        </svg>`;
      console.error('Speech recognition error:', event.error);
    };

    recognition.start();
  } else {
    // Fallback: set Play icon with slightly larger size for visibility
    startListeningBtn!.innerHTML = `
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" class="w-8 h-8 text-red-500">
        <path fill-rule="evenodd" d="M4.5 5.653c0-1.427 1.529-2.33 2.779-1.643l11.54 6.347c1.295.712 1.295 2.573 0 3.286L7.28 19.99c-1.25.687-2.779-.217-2.779-1.643V5.653z" clip-rule="evenodd" />
      </svg>`;
  }
}

document.getElementById('start-listening')!.addEventListener('click', () => {
  if (isListening) {
    recognition?.stop();
  } else {
    startListening();
  }
});


  </script>

<section id="voice-input" class="absolute top-0 right-0 flex items-center p-1">
  <button id="start-listening" class="flex items-center justify-center w-8 h-8 hover:bg-gray-100 transition-colors duration-300 ease-in-out rounded-full">
    <Microphone />
  </button>
</section>

